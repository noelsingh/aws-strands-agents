{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Strands Agents SDK\n",
    "\n",
    "Strands is AWS's framework for building production-ready AI agents that can:\n",
    "- Use multiple AI models (Bedrock, OpenAI, etc.)\n",
    "- Execute tools and take actions\n",
    "- Coordinate multiple agents in workflows\n",
    "- Provide enterprise-grade observability\n",
    "\n",
    "What we'll cover:\n",
    "1. Installing and basic setup\n",
    "2. Creating your first agent\n",
    "3. Debug logging and observability\n",
    "4. Switching between models\n",
    "5. Creating custom tools\n",
    "6. Using built-in tools\n",
    "7. Building multi-agent graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install the sdk run pip install `strands-agents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U strands-agents strands-agents-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create our first Agent..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "\n",
    "# Create an agent with default settings\n",
    "agent = Agent()\n",
    "\n",
    "# Ask the agent a question\n",
    "agent(\"What is AWS Strands Agents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Logs\n",
    "\n",
    "After running an agent, you can understand what happened during execution through traces and metrics.  Every agent invocation returns an `AgentResult` object with observability data.\n",
    "\n",
    "To enable debug logs in our agent, configure the `strands` logger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from strands import Agent\n",
    "\n",
    "# Enable Strands debug log level\n",
    "logging.getLogger(\"strands\").setLevel(logging.DEBUG)\n",
    "\n",
    "# Sets the logging format and streams logs to stderr\n",
    "logging.basicConfig(\n",
    "    format=\"%(levelname)s | %(name)s | %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "agent = Agent()\n",
    "\n",
    "agent(\"Hi whats your name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Providers\n",
    "\n",
    "Identifying a configured model provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent.model.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to specify an alternate model we can pass the `model ID` string directly, i'll specify Claude 3 Haiku `Cross Region Inference` profile id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(model=\"us.anthropic.claude-3-haiku-20240307-v1:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do a test query to confirm our model change occurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent(\"hi whats your name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you want more control of the model you specify i.e. defining `inference parameters`, you would create a model provider instance..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "\n",
    "# Create a BedrockModel\n",
    "bedrock_model = BedrockModel(\n",
    "    model_id=\"us.anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    region_name=\"us-east-1\",\n",
    "    temperatur=0.3\n",
    ")\n",
    "\n",
    "agent = Agent(model=bedrock_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Custom Tool and associating it with your Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent, tool\n",
    "\n",
    "@tool\n",
    "def greet_user(name: str, language: str = \"English\") -> str:\n",
    "    \"\"\"\n",
    "    Generate a personalized greeting in different languages.\n",
    "    \n",
    "    Args:\n",
    "        name: The person's name to greet\n",
    "        language: The language for the greeting (English, Spanish, French, Japanese)\n",
    "    \n",
    "    Returns:\n",
    "        A personalized greeting message\n",
    "    \"\"\"\n",
    "    greetings = {\n",
    "        \"English\": f\"Hello {name}! How are you today?\",\n",
    "        \"Spanish\": f\"¡Hola {name}! ¿Cómo estás?\",\n",
    "        \"French\": f\"Bonjour {name}! Comment allez-vous?\",\n",
    "        \"Japanese\": f\"こんにちは {name}さん! お元気ですか？\"\n",
    "    }\n",
    "    return greetings.get(language, f\"Hello {name}!\")\n",
    "\n",
    "agent = Agent(model=\"us.anthropic.claude-3-haiku-20240307-v1:0\",tools=[greet_user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural language invocation - agent decides when to use the tool\n",
    "result = agent(\"Please greet Noel in Spanish\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct method call\n",
    "result = agent.tool.greet_user(name=\"Noel\", language=\"French\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built in tools\n",
    "\n",
    "To work with the built in tools ensure you performed a `pip install strands-agents-tools`, Note Strands offers numerous built-in tools and you can also create your own custom tools, lets show an example of using a built in strands agent tool `calculator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets turn off DEBUG level logging\n",
    "import logging\n",
    "\n",
    "# Set to INFO level - only shows INFO, WARNING, ERROR, CRITICAL\n",
    "logging.getLogger(\"strands\").setLevel(logging.INFO)\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(levelname)s | %(name)s | %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "from strands_tools import calculator\n",
    "\n",
    "# Create agent with calculator tool\n",
    "agent = Agent(\n",
    "    tools=[calculator],\n",
    "    model=bedrock_model\n",
    "    #callback_handler=None  # Disable default callback handler\n",
    ")\n",
    "\n",
    "# Basic arithmetic examples\n",
    "result = agent(\"What is 25 * 47?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if you wanted to define a `Graph` to execute a sequence of steps\n",
    "\n",
    "You can use the Strands built-in `graph` tool to create and manage multi-agent systems using Strands SDK Graph implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "from strands_tools import graph, python_repl\n",
    "import os\n",
    "\n",
    "# Bypass tool consent\n",
    "os.environ[\"BYPASS_TOOL_CONSENT\"] = \"true\"\n",
    "\n",
    "# Create the main agent with the necessary tools\n",
    "agent = Agent(\n",
    "    model=\"us.anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    tools=[graph, python_repl],\n",
    "    callback_handler=None\n",
    ")\n",
    "\n",
    "# Step 1: Create the graph with very explicit instructions\n",
    "result = agent(\"\"\"\n",
    "Use the graph tool to create a graph. Call it with these exact parameters:\n",
    "\n",
    "action: \"create\"\n",
    "graph_id: \"code_pipeline\"\n",
    "topology: {\n",
    "    \"nodes\": [\n",
    "        {\n",
    "            \"id\": \"code_generator\",\n",
    "            \"role\": \"coder\",\n",
    "            \"system_prompt\": \"Generate Python code for the given task. Output only the code, no explanations or markdown.\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"code_executor\",\n",
    "            \"role\": \"executor\",\n",
    "            \"system_prompt\": \"Execute the provided Python code using the python_repl tool and report the results.\",\n",
    "            \"tools\": [\"python_repl\"]\n",
    "        }\n",
    "    ],\n",
    "    \"edges\": [\n",
    "        {\"from\": \"code_generator\", \"to\": \"code_executor\"}\n",
    "    ],\n",
    "    \"entry_points\": [\"code_generator\"]\n",
    "}\n",
    "\n",
    "Make sure to pass all these parameters exactly as shown.\n",
    "\"\"\")\n",
    "\n",
    "print(\"Graph creation result:\", result)\n",
    "\n",
    "# Check if graph was created successfully\n",
    "list_result = agent(\"Use the graph tool to list all graphs (action='list')\")\n",
    "print(\"\\nAvailable graphs:\", list_result)\n",
    "\n",
    "# Step 2: Execute a task through the graph\n",
    "result = agent(\"\"\"\n",
    "Use the graph tool with these parameters:\n",
    "- action: \"execute\"\n",
    "- graph_id: \"code_pipeline\"\n",
    "- task: \"Create a Python function that generates the Fibonacci sequence up to n terms, then call it with n=10 and print the result\"\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nExecution result:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human-in-the-Loop\n",
    "\n",
    "An important features for production AI systems is the ability to pause and get human approval or input before taking critical actions.  Strands provides the `handoff_to_user` tool for this.  Let's execute this from a python file in the command line so it can handle our input correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "from strands import Agent\n",
    "from strands_tools import handoff_to_user, file_write, shell\n",
    "import os\n",
    "\n",
    "os.environ[\"BYPASS_TOOL_CONSENT\"] = \"true\"  # For demo purposes only\n",
    "\n",
    "# Create an agent with human handoff capability\n",
    "agent = Agent(\n",
    "    model=\"us.anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    tools=[handoff_to_user, file_write, shell],\n",
    "    system_prompt=\"\"\"You are a helpful assistant that asks for human \n",
    "    confirmation before performing potentially dangerous operations.\"\"\"\n",
    ")\n",
    "\n",
    "# Example 1: Getting user approval before file operations\n",
    "result = agent(\"\"\"\n",
    "I need to delete an old log file named test.log located at /Users/nsinghsr/KiroProjects/Strands and \n",
    "create a new log file named newtest.log located in the same directory.  I want the content in the new log file\n",
    "to state \"test from noel aug 13th\".  Please handle this safely.\n",
    "\"\"\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
